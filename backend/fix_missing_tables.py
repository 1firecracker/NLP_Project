"""
ä¿®å¤é¢˜åº“ä¸­ç¼ºå¤±çš„è¡¨æ ¼
ä»åŸå§‹MDæ–‡ä»¶ä¸­æå–è¡¨æ ¼å¹¶æ·»åŠ åˆ°å¯¹åº”çš„é¢˜ç›®ä¸­
"""
import json
import re
from pathlib import Path

# å®šä¹‰æ–‡ä»¶è·¯å¾„
md_file = Path(r"C:\Users\19668\Desktop\workspace\NLP_Project-yhx_test\backend\uploads\exercises\c84f70ce-4f86-4a90-b1d8-158e9bdd0fc0\samples\final24\result.md")
qb_file = Path(r"C:\Users\19668\Desktop\workspace\NLP_Project-yhx_test\backend\data\c84f70ce-4f86-4a90-b1d8-158e9bdd0fc0\quiz\question_bank.json")

# è¯»å–MDæ–‡ä»¶
with open(md_file, 'r', encoding='utf-8') as f:
    md_content = f.read()

# æå–æ‰€æœ‰è¡¨æ ¼ (Table 1, Table 2, Table 3)
tables = {}

# æå– Table 1
table1_match = re.search(r'Table 1:.*?\n\n(<table>.*?</table>)', md_content, re.DOTALL)
if table1_match:
    tables['Table 1'] = table1_match.group(1).strip()
    print(f"âœ… æ‰¾åˆ° Table 1, é•¿åº¦: {len(tables['Table 1'])}")

# æå– Table 2
table2_match = re.search(r'Table 2:.*?\n\n(<table>.*?</table>)', md_content, re.DOTALL)
if table2_match:
    tables['Table 2'] = table2_match.group(1).strip()
    print(f"âœ… æ‰¾åˆ° Table 2, é•¿åº¦: {len(tables['Table 2'])}")

# æå– Table 3
table3_match = re.search(r'Table 3:.*?\n\n(<table>.*?</table>)', md_content, re.DOTALL)
if table3_match:
    tables['Table 3'] = table3_match.group(1).strip()
    print(f"âœ… æ‰¾åˆ° Table 3, é•¿åº¦: {len(tables['Table 3'])}")

# è¯»å–é¢˜åº“
with open(qb_file, 'r', encoding='utf-8') as f:
    qb_data = json.load(f)

# ä¿®å¤æ¯ä¸ªé¢˜ç›®
updated_count = 0
for question in qb_data['question_bank']['questions']:
    stem = question['stem']
    
    # æ£€æŸ¥é¢˜å¹²ä¸­æ˜¯å¦æåˆ°äº†Table 1/2/3
    for table_name, table_html in tables.items():
        if table_name in stem and '<table' not in stem:
            # åœ¨æåˆ°è¡¨æ ¼çš„å¥å­åæ’å…¥è¡¨æ ¼HTML
            # æŸ¥æ‰¾å¥å­ç»“æŸçš„ä½ç½®ï¼ˆå¥å·ã€é—®å·æˆ–æ¢è¡Œï¼‰
            pattern = rf'({re.escape(table_name)}[^.?!\n]*[.?!])'
            match = re.search(pattern, stem)
            if match:
                # åœ¨åŒ¹é…çš„å¥å­åæ’å…¥è¡¨æ ¼
                sentence_end = match.end()
                new_stem = stem[:sentence_end] + '\n\n' + table_html + '\n\n' + stem[sentence_end:]
                question['stem'] = new_stem
                updated_count += 1
                print(f"âœ… å·²å°† {table_name} æ·»åŠ åˆ°é¢˜ç›® {question['id']}")

# å¤‡ä»½åŸæ–‡ä»¶
backup_file = qb_file.with_suffix('.json.backup3')
import shutil
shutil.copy(qb_file, backup_file)
print(f"\nğŸ“¦ åŸæ–‡ä»¶å·²å¤‡ä»½åˆ°: {backup_file}")

# ä¿å­˜ä¿®å¤åçš„é¢˜åº“
with open(qb_file, 'w', encoding='utf-8') as f:
    json.dump(qb_data, f, ensure_ascii=False, indent=2)

print(f"âœ… å…±æ›´æ–° {updated_count} ä¸ªé¢˜ç›®")
print(f"âœ… é¢˜åº“å·²æ›´æ–°: {qb_file}")
print("\nè¯·é‡æ–°åŠ è½½å‰ç«¯é¡µé¢ä»¥æŸ¥çœ‹æ›´æ–°åçš„è¡¨æ ¼")
