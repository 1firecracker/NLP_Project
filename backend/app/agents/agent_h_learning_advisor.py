# -*- coding: utf-8 -*-
# ===========================================================
# æ–‡ä»¶ï¼šbackend/app/agents/agent_h_learning_advisor.py
# åŠŸèƒ½ï¼šAgent H - å­¦ä¹ è¯Šæ–­ä¸ä¸ªæ€§åŒ–å»ºè®®ç”Ÿæˆ
# è¯´æ˜ï¼šæ¥æ”¶ Agent G çš„è¯„åˆ†æŠ¥å‘Šï¼Œæ·±åº¦åˆ†æå­¦ç”Ÿè–„å¼±ç‚¹ï¼Œç”Ÿæˆé’ˆå¯¹æ€§å­¦ä¹ è·¯å¾„ä¸èµ„æºæ¨è
# ===========================================================

import os
import re
import json
import asyncio
import aiohttp
from datetime import datetime
from dotenv import load_dotenv
from typing import Dict, List
from collections import defaultdict

from app.agents.database.question_bank_storage import BASE_DATA_DIR

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
API_URL = os.getenv("LLM_BINDING_HOST", "https://api.siliconflow.cn/v1")
API_KEY = os.getenv("LLM_BINDING_API_KEY")
MODEL_NAME = os.getenv("LLM_MODEL", "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B")

HEADERS = {
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json",
}


def analyze_weak_points(grading_report: dict) -> dict:
    """
    åˆ†æè¯„åˆ†æŠ¥å‘Šï¼Œè¯†åˆ«è–„å¼±çŸ¥è¯†ç‚¹ä¸é¢˜å‹ã€‚
    è¿”å›ï¼š
    {
        "weak_knowledge_points": [{"name": "çŸ¥è¯†ç‚¹", "mastery": 0.45, "count": 3, "avg_score": 45}],
        "weak_question_types": [{"type": "ç®€ç­”é¢˜", "avg_score": 50, "count": 5}],
        "difficult_questions": [{"id": "Q003", "score": 20, "issues": [...]}],
        "overall_weaknesses": ["è®¡ç®—æ¨å¯¼ä¸å®Œæ•´", "æ¦‚å¿µç†è§£æ¨¡ç³Š"]
    }
    """
    per_q = grading_report.get("per_question", [])
    kp_analysis = grading_report.get("knowledgeAnalysis", {})
    
    # 1ï¸âƒ£ è–„å¼±çŸ¥è¯†ç‚¹ï¼ˆæŒæ¡åº¦ < 0.6ï¼‰
    weak_kps = []
    for kp, info in kp_analysis.items():
        mastery = info.get("masteryLevel", 0)
        if mastery < 0.6:
            weak_kps.append({
                "name": kp,
                "mastery": round(mastery, 3),
                "count": info.get("questionCount", 0),
                "performance": info.get("performance", "éœ€æ”¹è¿›")
            })
    
    # æŒ‰æŒæ¡åº¦æ’åºï¼ˆæœ€å¼±çš„æ’å‰é¢ï¼‰
    weak_kps.sort(key=lambda x: x["mastery"])
    
    # 2ï¸âƒ£ è–„å¼±é¢˜å‹ï¼ˆå¹³å‡åˆ† < 60ï¼‰
    type_scores = defaultdict(list)
    for q in per_q:
        qtype = q.get("question_type", "unknown")
        score = q.get("score", 0)
        type_scores[qtype].append(score)
    
    weak_types = []
    for qtype, scores in type_scores.items():
        avg = sum(scores) / len(scores) if scores else 0
        if avg < 60:
            weak_types.append({
                "type": qtype,
                "avg_score": round(avg, 1),
                "count": len(scores)
            })
    
    weak_types.sort(key=lambda x: x["avg_score"])
    
    # 3ï¸âƒ£ å¾—åˆ†æœ€ä½çš„é¢˜ç›®ï¼ˆ< 50 åˆ†ï¼‰
    difficult_qs = []
    for q in per_q:
        score = q.get("score", 0)
        if score < 50:
            difficult_qs.append({
                "id": q.get("id"),
                "score": score,
                "feedback": q.get("feedback", ""),
                "issues": q.get("issues", []),
                "knowledge_points": q.get("knowledge_points", [])
            })
    
    difficult_qs.sort(key=lambda x: x["score"])
    
    # 4ï¸âƒ£ æå–å¸¸è§é—®é¢˜ï¼ˆä» issues å­—æ®µæ±‡æ€»ï¼‰
    all_issues = []
    for q in per_q:
        all_issues.extend(q.get("issues", []))
    
    # ç®€å•é¢‘ç‡ç»Ÿè®¡
    issue_count = defaultdict(int)
    for issue in all_issues:
        issue_count[issue] += 1
    
    # å–å‰ 5 ä¸ªæœ€å¸¸è§é—®é¢˜
    overall_weaknesses = sorted(issue_count.items(), key=lambda x: -x[1])[:5]
    overall_weaknesses = [issue for issue, _ in overall_weaknesses]
    
    return {
        "weak_knowledge_points": weak_kps[:5],  # æœ€å¤š 5 ä¸ª
        "weak_question_types": weak_types[:3],  # æœ€å¤š 3 ä¸ª
        "difficult_questions": difficult_qs[:5],  # æœ€å¤š 5 é¢˜
        "overall_weaknesses": overall_weaknesses
    }


async def async_generate_learning_plan(session, weak_analysis: dict, student_name: str = "è¯¥å­¦ç”Ÿ"):
    """
    ä½¿ç”¨ LLM æ ¹æ®è–„å¼±ç‚¹åˆ†æç”Ÿæˆä¸ªæ€§åŒ–å­¦ä¹ è®¡åˆ’ã€‚
    è¿”å›ï¼š
    {
        "priority_topics": [{"topic": "çŸ¥è¯†ç‚¹A", "reason": "...", "resources": [...]}],
        "study_plan": "åˆ†é˜¶æ®µå­¦ä¹ å»ºè®®...",
        "practice_suggestions": ["å»ºè®®1", "å»ºè®®2"],
        "estimated_hours": 10
    }
    """
    weak_kps = weak_analysis.get("weak_knowledge_points", [])
    weak_types = weak_analysis.get("weak_question_types", [])
    weaknesses = weak_analysis.get("overall_weaknesses", [])
    
    # æ„é€  prompt
    prompt = f"""
ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„æ•™è‚²é¡¾é—®ã€‚è¯·æ ¹æ®ä»¥ä¸‹å­¦ç”Ÿï¼ˆ{student_name}ï¼‰çš„è€ƒè¯•è–„å¼±ç‚¹åˆ†æï¼Œç”Ÿæˆä¸ªæ€§åŒ–å­¦ä¹ å»ºè®®ï¼š

ã€è–„å¼±çŸ¥è¯†ç‚¹ã€‘
"""
    for kp in weak_kps[:3]:
        prompt += f"- {kp['name']}ï¼ˆæŒæ¡åº¦ï¼š{kp['mastery']*100:.1f}%ï¼Œæ¶‰åŠ {kp['count']} é¢˜ï¼‰\n"
    
    prompt += "\nã€è–„å¼±é¢˜å‹ã€‘\n"
    for wt in weak_types:
        prompt += f"- {wt['type']}ï¼ˆå¹³å‡åˆ†ï¼š{wt['avg_score']}ï¼‰\n"
    
    prompt += "\nã€å¸¸è§é—®é¢˜ã€‘\n"
    for w in weaknesses[:3]:
        prompt += f"- {w}\n"
    
    prompt += """
è¯·ç”Ÿæˆä»¥ä¸‹å†…å®¹ï¼ˆä¸¥æ ¼ JSON æ ¼å¼ï¼‰ï¼š
{
  "priority_topics": [
    {"topic": "çŸ¥è¯†ç‚¹åç§°", "reason": "ä¸ºä»€ä¹ˆä¼˜å…ˆå­¦ä¹ ï¼ˆ1å¥è¯ï¼‰", "resources": ["èµ„æºå»ºè®®1", "èµ„æºå»ºè®®2"]}
  ],
  "study_plan": "åˆ†é˜¶æ®µå­¦ä¹ è®¡åˆ’ï¼ˆ3-5 ä¸ªé˜¶æ®µï¼Œæ¯é˜¶æ®µ 1-2 å¥è¯ï¼‰",
  "practice_suggestions": ["å…·ä½“ç»ƒä¹ å»ºè®®1", "å…·ä½“ç»ƒä¹ å»ºè®®2", "..."],
  "estimated_hours": é¢„ä¼°éœ€è¦çš„å­¦ä¹ æ—¶é•¿ï¼ˆå°æ—¶ï¼Œæ•´æ•°ï¼‰
}

åªè¾“å‡º JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚
"""

    payload = {
        "model": MODEL_NAME,
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€åä¸“ä¸šçš„æ•™è‚²è§„åˆ’é¡¾é—®ï¼Œæ“…é•¿æ ¹æ®å­¦ç”Ÿè¡¨ç°ç”Ÿæˆé’ˆå¯¹æ€§å­¦ä¹ æ–¹æ¡ˆã€‚"},
            {"role": "user", "content": prompt}
        ],
        "max_tokens": 1200,
        "temperature": 0.7
    }

    for attempt in range(2):
        try:
            async with session.post(f"{API_URL}/chat/completions", headers=HEADERS, json=payload, timeout=180) as resp:
                res = await resp.json()
                content = res["choices"][0]["message"]["content"].strip()
                
                # æå– JSON
                m = re.search(r"\{[\s\S]*\}", content)
                if m:
                    try:
                        parsed = json.loads(m.group(0))
                        return parsed
                    except Exception:
                        pass
        except Exception as e:
            if attempt == 0:
                await asyncio.sleep(2)
            else:
                print(f"[âš ï¸ LLM ç”Ÿæˆå­¦ä¹ è®¡åˆ’å¤±è´¥] {e}")
                break
    
    # Fallbackï¼šåŸºäºè§„åˆ™ç”Ÿæˆç®€å•å»ºè®®
    priority = []
    for kp in weak_kps[:3]:
        priority.append({
            "topic": kp["name"],
            "reason": f"å½“å‰æŒæ¡åº¦ä»… {kp['mastery']*100:.0f}%ï¼Œéœ€è¦é‡ç‚¹åŠ å¼º",
            "resources": ["å¤ä¹ æ•™æç›¸å…³ç« èŠ‚", "å®Œæˆè¯¾åä¹ é¢˜", "è§‚çœ‹ç›¸å…³è§†é¢‘æ•™ç¨‹"]
        })
    
    suggestions = [
        "æ¯å¤©è‡³å°‘å¤ä¹  1 å°æ—¶è–„å¼±çŸ¥è¯†ç‚¹",
        "å®Œæˆ 10-15 é“ç›¸å…³ç»ƒä¹ é¢˜å¹¶æ€»ç»“é”™é¢˜",
        "å°è¯•ç”¨è‡ªå·±çš„è¯è§£é‡Šæ¦‚å¿µï¼Œæ£€éªŒç†è§£æ·±åº¦"
    ]
    
    if weak_types:
        suggestions.append(f"é’ˆå¯¹ {weak_types[0]['type']} è¿›è¡Œä¸“é¡¹è®­ç»ƒ")
    
    return {
        "priority_topics": priority,
        "study_plan": "ç¬¬ä¸€é˜¶æ®µï¼šå·©å›ºè–„å¼±çŸ¥è¯†ç‚¹åŸºç¡€æ¦‚å¿µï¼ˆ2-3 å¤©ï¼‰ï¼›ç¬¬äºŒé˜¶æ®µï¼šé’ˆå¯¹æ€§ç»ƒä¹ ä¸é”™é¢˜åˆ†æï¼ˆ3-4 å¤©ï¼‰ï¼›ç¬¬ä¸‰é˜¶æ®µï¼šç»¼åˆåº”ç”¨ä¸æ¨¡æ‹Ÿæµ‹è¯•ï¼ˆ2 å¤©ï¼‰ã€‚",
        "practice_suggestions": suggestions,
        "estimated_hours": len(weak_kps) * 3 + 5  # ç²—ç•¥ä¼°è®¡
    }


def run_agent_h(grading_report: dict, conversation_id: str, student_name: str = "å­¦ç”Ÿ") -> dict:
    """
    Agent H ä¸»å‡½æ•°ï¼šæ¥æ”¶è¯„åˆ†æŠ¥å‘Šï¼Œç”Ÿæˆå­¦ä¹ è¯Šæ–­ä¸å»ºè®®ã€‚
    
    Args:
        grading_report: Agent G è¿”å›çš„è¯„åˆ†æŠ¥å‘Š
        conversation_id: ä¼šè¯ ID
        student_name: å­¦ç”Ÿå§“å
    
    Returns:
        dict: åŒ…å«è–„å¼±ç‚¹åˆ†æ + å­¦ä¹ è®¡åˆ’çš„å®Œæ•´æŠ¥å‘Š
    """
    print(f"ğŸ§© [Agent H] å¼€å§‹ç”Ÿæˆå­¦ä¹ è¯Šæ–­ä¸å»ºè®®ï¼ˆå­¦ç”Ÿï¼š{student_name}ï¼‰...")
    
    # 1ï¸âƒ£ åˆ†æè–„å¼±ç‚¹
    weak_analysis = analyze_weak_points(grading_report)
    
    # 2ï¸âƒ£ è°ƒç”¨ LLM ç”Ÿæˆå­¦ä¹ è®¡åˆ’
    try:
        async def main():
            async with aiohttp.ClientSession() as session:
                return await async_generate_learning_plan(session, weak_analysis, student_name)
        
        learning_plan = asyncio.run(main())
    except Exception as e:
        print(f"[âŒ Agent H LLM è°ƒç”¨å¤±è´¥] {e}")
        # ä½¿ç”¨é™çº§æ–¹æ¡ˆ
        learning_plan = {
            "priority_topics": [],
            "study_plan": "è¯·æ ¹æ®è–„å¼±çŸ¥è¯†ç‚¹ï¼Œç³»ç»Ÿå¤ä¹ ç›¸å…³ç« èŠ‚å¹¶å®Œæˆé…å¥—ç»ƒä¹ ã€‚",
            "practice_suggestions": ["å¤ä¹ é”™é¢˜", "å®Œæˆè¯¾åä¹ é¢˜"],
            "estimated_hours": 8
        }
    
    # 3ï¸âƒ£ ç»„åˆå®Œæ•´æŠ¥å‘Š
    h_report = {
        "conversation_id": conversation_id,
        "student_name": student_name,
        "generated_at": datetime.now().isoformat(),
        "weak_analysis": weak_analysis,
        "learning_plan": learning_plan,
        "summary": {
            "weak_kp_count": len(weak_analysis["weak_knowledge_points"]),
            "difficult_q_count": len(weak_analysis["difficult_questions"]),
            "priority_count": len(learning_plan.get("priority_topics", [])),
            "estimated_hours": learning_plan.get("estimated_hours", 0)
        }
    }
    
    # 4ï¸âƒ£ ä¿å­˜åˆ°ç£ç›˜
    try:
        advisor_dir = os.path.join(BASE_DATA_DIR, conversation_id, "learning_advice")
        os.makedirs(advisor_dir, exist_ok=True)
        fname = f"advice_{student_name or 'anon'}_{datetime.now().strftime('%Y%m%d%H%M%S')}.json"
        fp = os.path.join(advisor_dir, fname)
        with open(fp, 'w', encoding='utf-8') as f:
            json.dump(h_report, f, ensure_ascii=False, indent=2)
        print(f"âœ… å­¦ä¹ å»ºè®®å·²ä¿å­˜è‡³: {fp}")
    except Exception as e:
        print(f"[âš ï¸ ä¿å­˜å­¦ä¹ å»ºè®®å¤±è´¥] {e}")
    
    print(f"ğŸ“š [Agent H] å®Œæˆå­¦ä¹ è¯Šæ–­ï¼šè¯†åˆ« {h_report['summary']['weak_kp_count']} ä¸ªè–„å¼±çŸ¥è¯†ç‚¹ï¼Œ"
          f"ç”Ÿæˆ {h_report['summary']['priority_count']} ä¸ªä¼˜å…ˆå­¦ä¹ ä¸»é¢˜ã€‚")
    
    return h_report


if __name__ == "__main__":
    # æµ‹è¯•ç”¨ä¾‹
    mock_report = {
        "per_question": [
            {"id": "Q001", "score": 80, "question_type": "é€‰æ‹©é¢˜", "issues": [], "knowledge_points": ["PythonåŸºç¡€"]},
            {"id": "Q002", "score": 40, "question_type": "ç®€ç­”é¢˜", "issues": ["ç¼ºå°‘æ¨å¯¼æ­¥éª¤"], "knowledge_points": ["æ•°æ®ç»“æ„"]},
            {"id": "Q003", "score": 30, "question_type": "ç¼–ç¨‹é¢˜", "issues": ["é€»è¾‘é”™è¯¯", "è¯­æ³•é”™è¯¯"], "knowledge_points": ["ç®—æ³•", "å¾ªç¯"]},
        ],
        "knowledgeAnalysis": {
            "PythonåŸºç¡€": {"masteryLevel": 0.8, "questionCount": 1, "performance": "è‰¯å¥½"},
            "æ•°æ®ç»“æ„": {"masteryLevel": 0.4, "questionCount": 1, "performance": "éœ€æ”¹è¿›"},
            "ç®—æ³•": {"masteryLevel": 0.3, "questionCount": 1, "performance": "éœ€æ”¹è¿›"},
        }
    }
    
    result = run_agent_h(mock_report, "test_conv", "æµ‹è¯•å­¦ç”Ÿ")
    print(json.dumps(result, ensure_ascii=False, indent=2))
