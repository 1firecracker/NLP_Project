# -*- coding: utf-8 -*-
# ===========================================================
# æ–‡ä»¶ï¼šbackend/app/agents/agent_a_data_preparation.py
# åŠŸèƒ½ï¼šAgent A - æ‰«æ Markdown æ ·å· â†’ è°ƒç”¨ LLM ç”Ÿæˆå«é¢˜å‹/éš¾åº¦/çŸ¥è¯†ç‚¹çš„å¤šå±‚é¢˜åº“ â†’ QuestionBank
# ===========================================================

import json
import os
import re
import time
from collections import Counter
from typing import List, Tuple, Dict

import requests
from openai import OpenAI  # type: ignore
from dotenv import load_dotenv  # type: ignore

from app.agents.shared_state import shared_state
from app.agents.database.question_bank_storage import save_question_bank
from app.agents.models.quiz_models import Question, QuestionBank, SubQuestion

# -----------------------------------------------------------
# ç¯å¢ƒé…ç½®
# -----------------------------------------------------------
load_dotenv()
API_URL = os.getenv("LLM_BINDING_HOST", "https://api.siliconflow.cn/v1")
API_KEY = os.getenv("LLM_BINDING_API_KEY")
MODEL_NAME = os.getenv("LLM_MODEL", "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B")
HEADERS = {
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json",
}
OPENAI_CLIENT = OpenAI(api_key=API_KEY, base_url=API_URL) if OpenAI else None
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))

PROMPT_TEMPLATE = """ä½ æ˜¯ä¸€åâ€œè¯•é¢˜æŠ½å–ä¸ç»“æ„åŒ–åŠ©æ‰‹â€ã€‚è¾“å…¥æ˜¯ä¸€ä»½ Markdown è¯•å·ï¼Œé¢˜ç›®ç¼–å·ã€åˆ†å€¼å’Œå­é—®æ ‡è®°å½¢å¼å¯èƒ½ä¸ç»Ÿä¸€ã€‚è¯·ä¸¥æ ¼è¾“å‡º JSON æ•°ç»„ï¼Œæ¯é“é¢˜åŠå…¶å­é¢˜éƒ½è¦åŒ…å«é¢˜å‹ã€éš¾åº¦ï¼ˆeasy/medium/hardï¼‰å’ŒçŸ¥è¯†ç‚¹ï¼š
[
  {{
    "id": "é¢˜ç›®ç¼–å·ï¼ˆå¦‚ 1ã€2ã€3ã€1(a)ï¼‰",
    "stem": "é¢˜å¹²å…¨æ–‡ï¼ˆå»æ‰é¢˜å·ã€åˆ†å€¼æç¤ºï¼‰",
    "score": é¢˜ç›®æ€»åˆ†ï¼ˆæ•°å­—ï¼Œç¼ºå¤±å¡« 0ï¼‰,
    "question_type": "short_answer | calculation | multiple_choice | single_choice | essay | programming | other",
    "difficulty": "easy | medium | hard",
    "knowledge_points": ["çŸ¥è¯†ç‚¹1", "çŸ¥è¯†ç‚¹2"],
    "sub_questions": [
        {{
            "label": "å­é—®æ ‡è®°ï¼ˆa/i ç­‰ï¼‰",
            "stem": "å­é—®é¢˜å†…å®¹",
            "score": å­é—®åˆ†å€¼ï¼ˆæ•°å­—ï¼Œç¼ºå¤±å¡« 0ï¼‰,
            "question_type": "å­é¢˜é¢˜å‹ï¼ŒåŒä¸Šå–å€¼èŒƒå›´",
            "difficulty": "easy | medium | hard",
            "knowledge_points": ["çŸ¥è¯†ç‚¹A", "çŸ¥è¯†ç‚¹B"],
            "sub_questions": [
                {{
                    "label": "æ›´ç»†ä¸€çº§å­é—®æ ‡è®°ï¼ˆå¦‚ a-1/i/1 ç­‰ï¼‰",
                    "stem": "æ›´ç»†ä¸€çº§å­é—®å†…å®¹",
                    "score": å­é—®åˆ†å€¼ï¼ˆæ•°å­—ï¼Œç¼ºå¤±å¡« 0ï¼‰,
                    "question_type": "å­é¢˜é¢˜å‹ï¼ŒåŒä¸Šå–å€¼èŒƒå›´",
                    "difficulty": "easy | medium | hard",
                    "knowledge_points": ["çŸ¥è¯†ç‚¹X"]
                }}
            ]
        }}
    ]
  }}
]
- å¦‚æœé¢˜ç›®æ²¡æœ‰å­é—®ï¼Œsub_questions è®¾ä¸ºç©ºæ•°ç»„ï¼›è‹¥å­é—®ä¸‹è¿˜æœ‰å­é—®ï¼Œç»§ç»­é€’å½’ä½¿ç”¨ä¸Šè¿°å­—æ®µã€‚
- åˆ†å€¼ç¼ºå¤±å¡« 0ï¼›é¢˜å‹æ— æ³•åˆ¤æ–­å¡« otherï¼›çŸ¥è¯†ç‚¹è‡³å°‘ç»™å‡ºä¸€é¡¹ï¼ˆç¡®å®æ— æ³•è¯†åˆ«å¯ä½¿ç”¨ ["é€šç”¨çŸ¥è¯†"]ï¼‰ã€‚
- ä¿ç•™ Markdown/LaTeX å…¬å¼å†…å®¹ï¼Œåªè¾“å‡ºåˆæ³• JSONï¼Œä¸è¦æ·»åŠ é¢å¤–è§£é‡Šæˆ–ä»£ç å—æ ‡è®°ã€‚

è¯·å¤„ç†ä»¥ä¸‹ Markdownï¼š
<<<BEGIN_MARKDOWN
{markdown}
<<<END_MARKDOWN
"""

# -----------------------------------------------------------
# Markdown æ–‡ä»¶æ‰«æ
# -----------------------------------------------------------

def _scan_markdown_files(conversation_id: str, provided_paths: List[str] = None) -> List[str]:
    """
    æ”¶é›†ä¼šè¯ä¸‹æ‰€æœ‰ .md æ–‡ä»¶ã€‚
    """
    if provided_paths:
        sanitized = [
            p for p in provided_paths
            if p and p.strip().upper() != "__AUTO__"
        ]
        if sanitized:
            return [p for p in sanitized if p.lower().endswith(".md") and os.path.exists(p)]

    base_dir = os.path.join(BASE_DIR, "uploads", "exercises", conversation_id, "samples")
    detected = []
    if not os.path.exists(base_dir):
        return detected

    for root, _, files in os.walk(base_dir):
        for f in files:
            if f.lower().endswith(".md"):
                detected.append(os.path.join(root, f))
    return detected


# -----------------------------------------------------------
# LLM è°ƒç”¨
# -----------------------------------------------------------

def _extract_json_array(text: str):
    """
    ä» LLM è¾“å‡ºä¸­æå– JSON æ•°ç»„ï¼Œæ”¯æŒåµŒå¥—ç»“æ„ã€‚
    ä¼˜å…ˆå°è¯•ç›´æ¥è§£ææ•´ä¸ªæ–‡æœ¬ï¼Œå¤±è´¥åˆ™å°è¯•æå–ä»£ç å—æˆ–æ•°ç»„ç‰‡æ®µã€‚
    """
    if not text:
        return []
    
    text = text.strip()
    
    def _safe_load(candidate: str):
        """å¤„ç† LaTeX è½¬ä¹‰å­—ç¬¦"""
        fixed = candidate
        # ä¿®å¤ LaTeX ä¸­å¸¸è§çš„éæ³• JSON è½¬ä¹‰
        latex_escapes = [
            (r'\{', r'\\{'),
            (r'\}', r'\\}'),
            (r'\(', r'\\('),
            (r'\)', r'\\)'),
            (r'\[', r'\\['),
            (r'\]', r'\\]'),
            (r'\_', r'\\_'),
            (r'\^', r'\\^'),
            (r'\&', r'\\&'),
            (r'\%', r'\\%'),
            (r'\$', r'\\$'),
            (r'\#', r'\\#'),
        ]
        for old, new in latex_escapes:
            fixed = re.sub(r'(?<!\\)' + re.escape(old), new, fixed)
        return json.loads(fixed)

    def _find_balanced_json_array(s: str, start_pos: int = 0) -> str:
        """ä½¿ç”¨æ‹¬å·åŒ¹é…æ‰¾åˆ°å®Œæ•´çš„ JSON æ•°ç»„"""
        arr_start = s.find('[', start_pos)
        if arr_start == -1:
            return None
        
        bracket_count = 0
        in_string = False
        escape_next = False
        
        for i in range(arr_start, len(s)):
            char = s[i]
            
            if escape_next:
                escape_next = False
                continue
            
            if char == '\\':
                escape_next = True
                continue
            
            if char == '"':
                in_string = not in_string
                continue
            
            if not in_string:
                if char == '[':
                    bracket_count += 1
                elif char == ']':
                    bracket_count -= 1
                    if bracket_count == 0:
                        return s[arr_start:i+1]
        
        return None

    # 1. å…ˆå»é™¤ ```json ... ``` ä»£ç å—æ ‡è®°
    code_block_match = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', text)
    if code_block_match:
        text = code_block_match.group(1).strip()
        print(f"[ğŸ“ æ£€æµ‹åˆ°ä»£ç å—ï¼Œå·²æå–å†…å®¹]")

    # 2. å°è¯•ç›´æ¥è§£ææ•´ä¸ªæ–‡æœ¬
    if text.startswith('['):
        try:
            return _safe_load(text)
        except json.JSONDecodeError as e:
            print(f"[âš ï¸ ç›´æ¥è§£æå¤±è´¥] {e}")
    
    # 3. ä½¿ç”¨æ‹¬å·åŒ¹é…æ‰¾åˆ°å®Œæ•´çš„ JSON æ•°ç»„
    json_str = _find_balanced_json_array(text)
    if json_str:
        try:
            return _safe_load(json_str)
        except json.JSONDecodeError as e:
            print(f"[âš ï¸ JSON è§£æå¤±è´¥] {e}")
            # å°è¯•ä¿®å¤å°¾éƒ¨é€—å·
            try:
                fixed = re.sub(r',\s*}', '}', json_str)
                fixed = re.sub(r',\s*]', ']', fixed)
                return _safe_load(fixed)
            except:
                pass
    
    return []


def _estimate_tokens(text: str) -> int:
    """ç²—ç•¥ä¼°ç®— token æ•°ï¼šä¸­æ–‡æŒ‰å­—ç¬¦ï¼Œè‹±æ–‡æŒ‰ç©ºæ ¼åˆ†è¯ï¼Œçº¦ 1.3 å€"""
    if not text:
        return 0
    # ç®€å•å¯å‘å¼ï¼šä¸­æ–‡å­—ç¬¦æ•° + è‹±æ–‡å•è¯æ•°
    import re
    cjk_count = len(re.findall(r'[\u4e00-\u9fff]', text))
    eng_words = len(re.findall(r'\b[a-zA-Z]+\b', text))
    return int((cjk_count + eng_words) * 1.3)



def extract_questions_via_llm(markdown_text: str, conversation_id: str, source_name: str) -> List[dict]:
    """
    è°ƒç”¨ LLM å°† Markdown è½¬ä¸ºç»“æ„åŒ–é¢˜ç›®åˆ—è¡¨ã€‚
    """
    if not markdown_text.strip():
        return []

    prompt = PROMPT_TEMPLATE.format(markdown=markdown_text)
    payload = {
        "model": MODEL_NAME,
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„è¯•é¢˜æŠ½å–ä¸“å®¶ï¼Œä¸“é—¨ä» Markdown è¯•å·ä¸­å®šä½é¢˜ç›®ã€‚"},
            {"role": "user", "content": prompt},
        ],
        "temperature": 0.2,
        "max_tokens": 4000,
    }
    # payload["response_format"] = {"type": "json_object"}

    # ä¼°ç®—è¾“å…¥ token æ•°
    total_text = payload["messages"][0]["content"] + payload["messages"][1]["content"]
    est_tokens = _estimate_tokens(total_text)
    print(f"ğŸ§¾ LLM é¢„è®¡ tokens: {est_tokens}")

    for attempt in range(2):
        try:
            start_ts = time.time()
            if OPENAI_CLIENT is not None:
                print("open ai client sending successfully")
                response = OPENAI_CLIENT.chat.completions.create(
                    model=MODEL_NAME,
                    messages=payload["messages"],
                    temperature=payload["temperature"],
                    max_tokens=payload["max_tokens"],
                    # response_format=payload["response_format"],
                    extra_body={
                        "thinking_budget": 256
                    }
                )
                cost = time.time() - start_ts
                print(f"â±ï¸ LLM è¯·æ±‚è€—æ—¶: {cost:.2f}s")
                content = response.choices[0].message.content or ""
            else:
                resp = requests.post(
                    f"{API_URL}/chat/completions",
                    headers=HEADERS,
                    json=payload,
                    timeout=500,
                )
                cost = time.time() - start_ts
                print(f"â±ï¸ LLM è¯·æ±‚è€—æ—¶: {cost:.2f}s")
                resp.raise_for_status()
                data = resp.json()
                content = data["choices"][0]["message"]["content"]

            # ä¿å­˜åŸå§‹è¾“å‡º
            debug_dir = os.path.join(BASE_DIR, "data", conversation_id, "debug")
            os.makedirs(debug_dir, exist_ok=True)
            debug_file = os.path.join(debug_dir, f"agent_a_{source_name}_attempt{attempt+1}.txt")
            with open(debug_file, "w", encoding="utf-8") as dbg:
                dbg.write(content)
            print(f"ğŸ“ LLM åŸå§‹è¾“å‡ºå·²ä¿å­˜ï¼š{debug_file}")

            parsed = _extract_json_array(content)
            if parsed:
                return parsed
            print(f"[âš ï¸ LLM è¿”å›æ— æ³•è§£æ JSONï¼Œå°è¯•é‡è¯•] attempt={attempt+1}")
        except requests.RequestException as e:
            cost = time.time() - start_ts if 'start_ts' in locals() else 0.0
            print(f"â±ï¸ LLM è¯·æ±‚è€—æ—¶: {cost:.2f}s")
            print(f"[âš ï¸ LLM è¯·æ±‚å¤±è´¥ attempt={attempt+1}] {e}")
    return []


# -----------------------------------------------------------
# Question å¯¹è±¡æ„å»º
# -----------------------------------------------------------

def _parse_sub_questions(entries: List[dict]) -> List[SubQuestion]:
    """é€’å½’è§£æå­é—®é¢˜åˆ—è¡¨"""
    parsed: List[SubQuestion] = []
    if not isinstance(entries, list):
        return parsed

    for index, entry in enumerate(entries, 1):
        if not isinstance(entry, dict):
            continue
        label_raw = entry.get("label", "")
        label = str(label_raw).strip() if label_raw is not None else ""
        stem_raw = entry.get("stem", "")
        stem = str(stem_raw).strip() if stem_raw is not None else ""
        if not stem:
            continue
        score_value = entry.get("score", 0)
        if isinstance(score_value, (int, float)):
            score = int(score_value)
        else:
            score = 0
        qtype_raw = entry.get("question_type", "short_answer")
        qtype = str(qtype_raw).strip() if qtype_raw is not None else "short_answer"
        difficulty_raw = entry.get("difficulty", "medium")
        difficulty = str(difficulty_raw).strip() if difficulty_raw is not None else "medium"
        kp_raw = entry.get("knowledge_points", [])
        kp_list = []
        if isinstance(kp_raw, list):
            kp_list = [str(k).strip() for k in kp_raw if str(k).strip()]
        if not kp_list:
            kp_list = ["é€šç”¨çŸ¥è¯†"]
        child_entries = entry.get("sub_questions", [])
        children = _parse_sub_questions(child_entries) if isinstance(child_entries, list) else []
        label_final = label if label else f"sub_{index}"
        parsed.append(
            SubQuestion(
                label=label_final,
                stem=stem,
                score=score,
                question_type=qtype or "short_answer",
                difficulty=difficulty or "medium",
                knowledge_points=kp_list,
                sub_questions=children,
            )
        )
    return parsed


def _convert_items_to_questions(items: List[dict], source_label: str) -> List[Question]:
    """
    å°† LLM è¿”å›çš„é¢˜ç›®åˆ—è¡¨è½¬æ¢ä¸º Question å¯¹è±¡ï¼Œä¿ç•™åµŒå¥—çš„ sub_questions ç»“æ„ã€‚
    """
    questions: List[Question] = []
    for idx, item in enumerate(items, 1):
        if not isinstance(item, dict):
            continue
        stem_raw = item.get("stem", "")
        stem = str(stem_raw).strip() if stem_raw is not None else ""
        if not stem:
            continue
        qid_raw = item.get("id", f"Q{idx:03d}")
        qid = str(qid_raw).strip() if qid_raw is not None else f"Q{idx:03d}"
        qtype_raw = item.get("question_type", "short_answer")
        qtype = str(qtype_raw).strip() if qtype_raw is not None else "short_answer"
        score_value = item.get("score", 0)
        if isinstance(score_value, (int, float)):
            score = int(score_value)
        else:
            score = 0
        difficulty_raw = item.get("difficulty", "medium")
        difficulty = str(difficulty_raw).strip() if difficulty_raw is not None else "medium"
        kp_raw = item.get("knowledge_points", [])
        kp_list = []
        if isinstance(kp_raw, list):
            kp_list = [str(k).strip() for k in kp_raw if str(k).strip()]
        if not kp_list:
            kp_list = ["é€šç”¨çŸ¥è¯†"]
        sub_questions = _parse_sub_questions(item.get("sub_questions", []))

        tags = [f"source:{source_label}", f"score:{score}"]

        question = Question(
            id=qid if qid else f"Q{idx:03d}",
            stem=stem,
            answer="ï¼ˆå¾…è¡¥å……ï¼‰",
            difficulty=difficulty or "medium",
            knowledge_points=kp_list,
            question_type=qtype or "short_answer",
            tags=tags,
            sub_questions=sub_questions,
        )
        questions.append(question)
    return questions


def _compute_distribution(questions: List[Question]) -> Dict[str, Dict[str, float]]:
    """
    ç»Ÿè®¡é¢˜å‹/éš¾åº¦/çŸ¥è¯†ç‚¹åˆ†å¸ƒï¼Œè¾“å‡ºä¸åŸ Agent C ç›¸åŒç»“æ„ï¼š
    {
        "conversation_id": ...,
        "total_questions": ...,
        "type_distribution": {...},
        "difficulty_distribution": {...},
        "knowledge_point_distribution": {...}
    }
    """
    type_counter = Counter()
    difficulty_counter = Counter()
    knowledge_counter = Counter()

    def traverse_question(q: Question):
        type_counter[q.question_type or "æœªçŸ¥ç±»å‹"] += 1
        difficulty_counter[q.difficulty or "medium"] += 1
        if q.knowledge_points:
            for kp in q.knowledge_points:
                if kp:
                    knowledge_counter[kp] += 1
        else:
            knowledge_counter["é€šç”¨çŸ¥è¯†"] += 1
        if q.sub_questions:
            for sub in q.sub_questions:
                # å°† SubQuestion è½¬ä¸º Question è§†è§’ç»Ÿè®¡
                sub_q = Question(
                    id=f"{q.id}-{sub.label}",
                    stem=sub.stem,
                    answer="ï¼ˆå­é—®ï¼‰",
                    difficulty=sub.difficulty or "medium",
                    knowledge_points=sub.knowledge_points or ["é€šç”¨çŸ¥è¯†"],
                    question_type=sub.question_type or "short_answer",
                    tags=[],
                    sub_questions=sub.sub_questions,
                )
                traverse_question(sub_q)

    for q in questions:
        traverse_question(q)

    def _calc(counter: Counter):
        total = sum(counter.values())
        if total == 0:
            return {}
        return {k: round(v / total, 4) for k, v in counter.items()}

    return {
        "total_questions": len(questions),
        "type_distribution": _calc(type_counter),
        "difficulty_distribution": _calc(difficulty_counter),
        "knowledge_point_distribution": _calc(knowledge_counter),
    }


# -----------------------------------------------------------
# ä¸»æ‰§è¡Œå‡½æ•°
# -----------------------------------------------------------

def run_agent_a(conversation_id: str, file_paths: List[str] = None) -> QuestionBank:
    print(f"ğŸ§© [Agent A] Markdown æŠ½é¢˜å¼€å§‹ï¼Œä¼šè¯ID: {conversation_id}")

    md_files = _scan_markdown_files(conversation_id, file_paths)
    if not md_files:
        print(f"âš ï¸ ä¼šè¯ {conversation_id} æœªæ‰¾åˆ°ä»»ä½• .md æ ·å·ï¼Œè¿”å›ç©ºé¢˜åº“äº¤ç”± Agent E å¤„ç†ã€‚")
        qb = QuestionBank(questions=[], source_docs=[])
        shared_state.question_bank = qb
        shared_state.source_text = ""
        return qb

    print(f"ğŸ‘‰ å·²å‘ç° {len(md_files)} ä¸ª Markdown æ ·å·ï¼š")
    for f in md_files:
        print(f"   - {f}")

    aggregated_texts = []
    all_questions: List[Question] = []
    max_retries = 2  # è§£æå¤±è´¥æ—¶æœ€å¤šé‡è¯•æ¬¡æ•°
    
    for md_path in md_files:
        try:
            with open(md_path, "r", encoding="utf-8") as f:
                content = f.read()
        except Exception as e:
            print(f"[âš ï¸ æ— æ³•è¯»å–æ–‡ä»¶] {md_path}: {e}")
            continue

        aggregated_texts.append(f"\n\n# Source: {md_path}\n{content}")
        source_name = os.path.splitext(os.path.basename(md_path))[0]
        relative_name = os.path.relpath(md_path, os.path.join(BASE_DIR, "uploads"))

        # å¸¦é‡è¯•çš„è§£æé€»è¾‘
        llm_items = None
        for retry in range(max_retries + 1):
            attempt_name = f"{source_name}_retry{retry}" if retry > 0 else source_name
            llm_items = extract_questions_via_llm(content, conversation_id, attempt_name)
            if llm_items:
                break
            if retry < max_retries:
                print(f"[ğŸ”„ è§£æç»“æœä¸ºç©ºï¼Œæ­£åœ¨é‡è¯• {retry + 1}/{max_retries}] {md_path}")
                time.sleep(1)  # é‡è¯•å‰ç­‰å¾… 1 ç§’
        
        if not llm_items:
            print(f"[âŒ é‡è¯• {max_retries} æ¬¡åä»æœªè§£æåˆ°é¢˜ç›®] {md_path}")
            continue
            
        questions = _convert_items_to_questions(llm_items, relative_name)
        all_questions.extend(questions)
        print(f"âœ… {md_path} è§£æå¾—åˆ° {len(questions)} é“é¢˜")

    if not all_questions:
        print("âš ï¸ æ‰€æœ‰ Markdown æ ·å·å‡æœªæˆåŠŸæŠ½å–é¢˜ç›®ï¼Œè¿”å›ç©ºé¢˜åº“äº¤ç”± Agent E å¤„ç†ã€‚")
        qb = QuestionBank(questions=[], source_docs=md_files)
        shared_state.question_bank = qb
        shared_state.source_text = "\n".join(aggregated_texts)
        return qb

    qb = QuestionBank(questions=all_questions, source_docs=md_files)
    shared_state.question_bank = qb
    shared_state.source_text = "\n".join(aggregated_texts)

    # ç»Ÿè®¡åˆ†å¸ƒå¹¶å†™å…¥ shared_state
    distribution = _compute_distribution(all_questions)
    distribution_model = {
        "conversation_id": conversation_id,
        "total_questions": distribution.get("total_questions", len(all_questions)),
        "type_distribution": distribution.get("type_distribution", {}),
        "difficulty_distribution": distribution.get("difficulty_distribution", {}),
        "knowledge_point_distribution": distribution.get("knowledge_point_distribution", {}),
    }
    shared_state.distribution_model = distribution_model

    # ä¿å­˜åˆ†å¸ƒæ–‡ä»¶ï¼Œä¾¿äºæ›¿ä»£ Agent C
    dist_dir = os.path.join(BASE_DIR, "data", conversation_id)
    os.makedirs(dist_dir, exist_ok=True)
    dist_path = os.path.join(dist_dir, "distribution.json")
    with open(dist_path, "w", encoding="utf-8") as f:
        json.dump(distribution_model, f, ensure_ascii=False, indent=2)
    print(f"ğŸ“Š é¢˜å‹/éš¾åº¦/çŸ¥è¯†ç‚¹åˆ†å¸ƒå·²ç”Ÿæˆï¼š{dist_path}")

    save_path = save_question_bank(conversation_id, qb)
    print(f"âœ… Agent A å®Œæˆï¼Œå…±æŠ½å– {len(all_questions)} é¢˜ã€‚é¢˜åº“å·²ä¿å­˜ï¼š{save_path}")
    return qb
