# ä¸´æ—¶è¡¥ä¸æ–‡ä»¶ - æ·»åŠ æ¸…é™¤ç¼“å­˜åŠŸèƒ½å’Œæ”¹è¿›ç”Ÿæˆé€»è¾‘
# å°†æ­¤ä»£ç åˆå¹¶åˆ° exercise_service.py çš„ ExerciseService ç±»ä¸­

def _clear_generated_cache(self, conversation_id: str):
    """
    æ¸…é™¤æŒ‡å®šä¼šè¯çš„ç”Ÿæˆé¢˜åº“ç¼“å­˜ï¼ˆç£ç›˜æ–‡ä»¶å’Œå†…å­˜çŠ¶æ€ï¼‰
    """
    import os
    from app.agents.database.question_bank_storage import BASE_DATA_DIR
    from app.agents.shared_state import shared_state
    import shutil
    
    # æ¸…é™¤å†…å­˜ç¼“å­˜
    shared_state.reset()
    
    # æ¸…é™¤ç£ç›˜æ–‡ä»¶ï¼ˆ_generated, _corrected, _gradedï¼‰
    suffixes = ['_generated', '_corrected', '_graded']
    for suffix in suffixes:
        cache_id = f"{conversation_id}{suffix}"
        cache_dir = os.path.join(BASE_DATA_DIR, cache_id)
        if os.path.exists(cache_dir):
            try:
                shutil.rmtree(cache_dir)
                print(f"[ğŸ—‘ï¸ å·²æ¸…é™¤ç¼“å­˜] {cache_dir}")
            except Exception as e:
                print(f"[âš ï¸ æ¸…é™¤ç¼“å­˜å¤±è´¥] {cache_dir}: {e}")


# æ›¿æ¢åŸæœ‰çš„ generate_questions æ–¹æ³•
def generate_questions_NEW(self, conversation_id: str, up_to: str = "F") -> Dict:
    """
    åŸºäºå½“å‰ä¼šè¯å·²ä¸Šä¼ å¹¶è§£æå®Œæˆçš„æ ·æœ¬è¯•é¢˜ï¼Œ
    å¯åŠ¨æ•´æ¡å‡ºé¢˜ Agent é“¾ï¼ˆA~Fï¼‰ï¼Œå¹¶è¿”å›ç”Ÿæˆç»“æœæ¦‚è¦ã€‚

    æ”¹è¿›ç‚¹ï¼š
    - ä¸¥æ ¼ä½¿ç”¨å½“å‰ conversation_idï¼Œä¸å†è‡ªåŠ¨å…œåº•åˆ°å…¶ä»–ä¼šè¯
    - æ¯æ¬¡ç”Ÿæˆå‰æ¸…é™¤æ—§ç¼“å­˜ï¼Œç¡®ä¿ç”Ÿæˆæ–°é¢˜ç›®
    - æ›´æ˜ç¡®çš„é”™è¯¯æç¤º
    """
    from app.agents.quiz_graph import run_agent_chain, validate_outputs
    from app.agents.database.question_bank_storage import load_question_bank
    from app.agents.shared_state import shared_state
    
    # åªä½¿ç”¨å½“å‰ conversation_idï¼Œä¸å†è‡ªåŠ¨æŸ¥æ‰¾å…¶ä»–ä¼šè¯
    effective_id = conversation_id
    samples = self.list_samples(conversation_id)

    # æ£€æŸ¥å½“å‰ä¼šè¯æ˜¯å¦æœ‰å·²å®Œæˆçš„æ ·æœ¬
    if not samples:
        raise ValueError(
            f"å½“å‰ä¼šè¯ [{conversation_id}] æœªæ‰¾åˆ°ä»»ä½•æ ·æœ¬è¯•å·ã€‚\n"
            "è¯·å…ˆåœ¨ã€æ ·æœ¬è¯•å·ã€‘æ¨¡å—ä¸Šä¼  PDF/DOCX/TXT æ–‡ä»¶ï¼Œå¹¶ç­‰å¾…è§£æå®Œæˆåå†ç”Ÿæˆè¯•é¢˜ã€‚"
        )
    
    completed_samples = [s for s in samples if s.get("status") == "completed"]
    if not completed_samples:
        pending_count = len([s for s in samples if s.get("status") == "pending"])
        if pending_count > 0:
            raise ValueError(
                f"å½“å‰ä¼šè¯æœ‰ {pending_count} ä¸ªæ ·æœ¬æ­£åœ¨è§£æä¸­ï¼Œè¯·ç¨ç­‰ç‰‡åˆ»åå†ç”Ÿæˆè¯•é¢˜ã€‚"
            )
        else:
            raise ValueError(
                f"å½“å‰ä¼šè¯çš„æ ·æœ¬è§£æå¤±è´¥ã€‚è¯·é‡æ–°ä¸Šä¼ æ ·æœ¬è¯•å·æˆ–æ£€æŸ¥æ–‡ä»¶æ ¼å¼ã€‚"
            )

    # æ¸…é™¤æ—§ç¼“å­˜ï¼ˆç¡®ä¿ç”Ÿæˆæ–°é¢˜ç›®ï¼‰
    print(f"[ğŸ”„ æ¸…é™¤æ—§ç¼“å­˜] ä¼šè¯ {effective_id}")
    self._clear_generated_cache(effective_id)
    
    print(f"[AgentPipeline] ä½¿ç”¨ä¼šè¯ {effective_id} ç”Ÿæˆæ–°é¢˜ç›®ï¼ˆæ‰¾åˆ° {len(completed_samples)} ä¸ªå·²å®Œæˆæ ·æœ¬ï¼‰")

    # å¯åŠ¨ Agent é“¾
    run_agent_chain(effective_id, ["__AUTO__"], up_to=up_to)

    # ç®¡é“å¥åº·æ£€æŸ¥ï¼ˆA~F å“ªäº›æˆåŠŸ/ç¼ºå¤±ï¼‰
    pipeline_status = validate_outputs(effective_id)

    # è½½å…¥ç”Ÿæˆåçš„é¢˜åº“ï¼ˆ<conversation_id>_generatedï¼‰
    generated_id = f"{effective_id}_generated"
    qb_generated = load_question_bank(generated_id)
    if qb_generated is None or not getattr(qb_generated, "questions", None):
        raise ValueError("é¢˜ç›®ç”Ÿæˆæµç¨‹å·²å®Œæˆï¼Œä½†æœªæ‰¾åˆ°ç”Ÿæˆé¢˜åº“æ–‡ä»¶ã€‚")

    question_count = len(qb_generated.questions)

    # æ‹¿åˆ° Agent F çš„è´¨é‡æŠ¥å‘Šï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    quality_report = getattr(shared_state, "quality_report", None)

    return {
        "conversation_id": effective_id,
        "generated_conversation_id": generated_id,
        "question_count": question_count,
        "pipeline_status": pipeline_status,
        "quality_report": quality_report,
    }
