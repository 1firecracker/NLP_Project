"""å®Œæ•´ä¿®å¤ exercise_service.py"""

filepath = r'c:\Users\19668\Desktop\workspace\NLP_Project\backend\app\services\exercise_service.py'

with open(filepath, 'r', encoding='utf-8') as f:
    lines = f.readlines()

# æ‰¾åˆ° generate_questions æ–¹æ³•å¼€å§‹çš„è¡Œ
start_idx = None
for i, line in enumerate(lines):
    if 'def generate_questions(self, conversation_id: str, up_to: str = "F") -> Dict:' in line:
        start_idx = i
        break

if start_idx is None:
    print("âŒ æœªæ‰¾åˆ° generate_questions æ–¹æ³•")
    exit(1)

# æ‰¾åˆ°æ–¹æ³•ä½“å¼€å§‹ï¼ˆæ–‡æ¡£å­—ç¬¦ä¸²åï¼‰
doc_end = None
for i in range(start_idx + 1, min(start_idx + 20, len(lines))):
    if '"""' in lines[i] and i > start_idx + 1:
        doc_end = i
        break

if doc_end is None:
    print("âŒ æœªæ‰¾åˆ°æ–‡æ¡£å­—ç¬¦ä¸²ç»“æŸ")
    exit(1)

# æ‰¾åˆ°ä¸‹ä¸€ä¸ªæ–¹æ³•å¼€å§‹çš„è¡Œï¼ˆæˆ–æ–‡ä»¶ç»“æŸï¼‰
next_method = None
for i in range(doc_end + 1, len(lines)):
    if lines[i].strip().startswith('def ') and not lines[i].strip().startswith('# '):
        next_method = i
        break

if next_method is None:
    next_method = len(lines)

# æ–°çš„æ–¹æ³•å®ç°
new_implementation = '''        # åªä½¿ç”¨å½“å‰ conversation_idï¼Œä¸å†è‡ªåŠ¨æŸ¥æ‰¾å…¶ä»–ä¼šè¯
        effective_id = conversation_id
        samples = self.list_samples(conversation_id)

        # æ£€æŸ¥å½“å‰ä¼šè¯æ˜¯å¦æœ‰å·²å®Œæˆçš„æ ·æœ¬
        if not samples:
            raise ValueError(
                f"å½“å‰ä¼šè¯ [{conversation_id}] æœªæ‰¾åˆ°ä»»ä½•æ ·æœ¬è¯•å·ã€‚\\n"
                "è¯·å…ˆåœ¨ã€æ ·æœ¬è¯•å·ã€‘æ¨¡å—ä¸Šä¼  PDF/DOCX/TXT æ–‡ä»¶ï¼Œå¹¶ç­‰å¾…è§£æå®Œæˆåå†ç”Ÿæˆè¯•é¢˜ã€‚"
            )
        
        completed_samples = [s for s in samples if s.get("status") == "completed"]
        if not completed_samples:
            pending_count = len([s for s in samples if s.get("status") == "pending"])
            if pending_count > 0:
                raise ValueError(
                    f"å½“å‰ä¼šè¯æœ‰ {pending_count} ä¸ªæ ·æœ¬æ­£åœ¨è§£æä¸­ï¼Œè¯·ç¨ç­‰ç‰‡åˆ»åå†ç”Ÿæˆè¯•é¢˜ã€‚"
                )
            else:
                raise ValueError(
                    f"å½“å‰ä¼šè¯çš„æ ·æœ¬è§£æå¤±è´¥ã€‚è¯·é‡æ–°ä¸Šä¼ æ ·æœ¬è¯•å·æˆ–æ£€æŸ¥æ–‡ä»¶æ ¼å¼ã€‚"
                )

        # æ¸…é™¤æ—§ç¼“å­˜ï¼ˆç¡®ä¿ç”Ÿæˆæ–°é¢˜ç›®ï¼‰
        print(f"[ğŸ”„ æ¸…é™¤æ—§ç¼“å­˜] ä¼šè¯ {effective_id}")
        self._clear_generated_cache(effective_id)
        
        print(f"[AgentPipeline] ä½¿ç”¨ä¼šè¯ {effective_id} ç”Ÿæˆæ–°é¢˜ç›®ï¼ˆæ‰¾åˆ° {len(completed_samples)} ä¸ªå·²å®Œæˆæ ·æœ¬ï¼‰")

        # 2) å¯åŠ¨ Agent é“¾
        #    Agent A ä¼šåœ¨ run_agent_a ä¸­ä½¿ç”¨ "__AUTO__" è‡ªåŠ¨æ‰«æ backend/uploads/exercises ä¸‹çš„ text.txt
        run_agent_chain(effective_id, ["__AUTO__"], up_to=up_to)

        # 3) ç®¡é“å¥åº·æ£€æŸ¥ï¼ˆA~F å“ªäº›æˆåŠŸ/ç¼ºå¤±ï¼‰
        pipeline_status = validate_outputs(effective_id)

        # 4) è½½å…¥ç”Ÿæˆåçš„é¢˜åº“ï¼ˆ<conversation_id>_generatedï¼‰
        generated_id = f"{effective_id}_generated"
        qb_generated = load_question_bank(generated_id)
        if qb_generated is None or not getattr(qb_generated, "questions", None):
            raise ValueError("é¢˜ç›®ç”Ÿæˆæµç¨‹å·²å®Œæˆï¼Œä½†æœªæ‰¾åˆ°ç”Ÿæˆé¢˜åº“æ–‡ä»¶ã€‚")

        question_count = len(qb_generated.questions)

        # 5) æ‹¿åˆ° Agent F çš„è´¨é‡æŠ¥å‘Šï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        quality_report = getattr(shared_state, "quality_report", None)

        return {
            "conversation_id": effective_id,
            "generated_conversation_id": generated_id,
            "question_count": question_count,
            "pipeline_status": pipeline_status,
            "quality_report": quality_report,
        }

'''

# ä¿ç•™æ–¹æ³•å®šä¹‰å’Œæ–‡æ¡£å­—ç¬¦ä¸²ï¼Œæ›¿æ¢å®ç°
new_lines = lines[:doc_end + 1] + [new_implementation] + lines[next_method:]

with open(filepath, 'w', encoding='utf-8') as f:
    f.writelines(new_lines)

print(f"âœ… å·²æ›´æ–° generate_questions æ–¹æ³• (è¡Œ {start_idx + 1} åˆ° {next_method})")
